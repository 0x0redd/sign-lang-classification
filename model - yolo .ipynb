{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_VIDEO_DATASET_PATH = \"SignLanguageDataset\"  # <--- UPDATE THIS PATH to your raw videos\n",
    "BASE_OUTPUT_PATH_FRAMES = \"SignLanguage_Processed_Frames\" # Root for frame-based processing\n",
    "YOLO_FRAME_DATASET_ROOT = os.path.join(BASE_OUTPUT_PATH_FRAMES, \"YOLO_Frames_Dataset\") # Output for YOLOv8 cls\n",
    "\n",
    "# Video Splitting Parameters\n",
    "VIDEO_SPLIT_PATH = os.path.join(BASE_OUTPUT_PATH_FRAMES, \"video_splits_for_frames\")\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15 # YOLOv8 training will use this as its validation set\n",
    "TEST_RATIO = 0.15 # This will be a hold-out test set\n",
    "\n",
    "# Frame Extraction Parameters\n",
    "N_FRAMES_TO_EXTRACT = 16  # Number of frames to extract per video. Adjust as needed.\n",
    "                            # Too few might miss the sign, too many increases data size.\n",
    "IMAGE_SAVE_FORMAT = \".jpg\" # or \".png\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(BASE_OUTPUT_PATH_FRAMES, exist_ok=True)\n",
    "os.makedirs(YOLO_FRAME_DATASET_ROOT, exist_ok=True)\n",
    "os.makedirs(VIDEO_SPLIT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset Splitting (Re-using the function from previous script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_dataset(\n",
    "    raw_dataset_path,\n",
    "    output_split_path,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    random_seed=42,\n",
    "):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1\"\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    if not os.path.exists(raw_dataset_path):\n",
    "        print(f\"Error: Raw dataset path '{raw_dataset_path}' does not exist.\")\n",
    "        return False\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_folder = os.path.join(output_split_path, split)\n",
    "        os.makedirs(split_folder, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting dataset split from '{raw_dataset_path}' into '{output_split_path}'...\")\n",
    "    for class_name in os.listdir(raw_dataset_path):\n",
    "        class_dir = os.path.join(raw_dataset_path, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "\n",
    "        video_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
    "        if not video_files:\n",
    "            print(f\"Warning: No video files found in class '{class_name}'.\")\n",
    "            continue\n",
    "        \n",
    "        random.shuffle(video_files)\n",
    "        n_total = len(video_files)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        n_test = n_total - n_train - n_val\n",
    "        if n_test < 0: n_test = 0\n",
    "\n",
    "        splits_data = {\n",
    "            'train': video_files[:n_train],\n",
    "            'val': video_files[n_train : n_train + n_val],\n",
    "            'test': video_files[n_train + n_val :]\n",
    "        }\n",
    "        \n",
    "        current_assigned_count = len(splits_data['train']) + len(splits_data['val']) + len(splits_data['test'])\n",
    "        if current_assigned_count < n_total:\n",
    "            remaining_files = video_files[current_assigned_count:]\n",
    "            if len(splits_data['test']) < n_test and test_ratio > 0:\n",
    "                 splits_data['test'].extend(remaining_files)\n",
    "            elif len(splits_data['val']) < n_val and val_ratio > 0 :\n",
    "                 splits_data['val'].extend(remaining_files)\n",
    "            else:\n",
    "                 splits_data['train'].extend(remaining_files)\n",
    "        \n",
    "        for split_name, files_in_split in splits_data.items():\n",
    "            dest_class_dir = os.path.join(output_split_path, split_name, class_name)\n",
    "            os.makedirs(dest_class_dir, exist_ok=True)\n",
    "            for file_name in files_in_split:\n",
    "                src_file = os.path.join(class_dir, file_name)\n",
    "                dest_file = os.path.join(dest_class_dir, file_name)\n",
    "                shutil.copy2(src_file, dest_file) # Always copy for this frame extraction pipeline\n",
    "        \n",
    "        print(f\"Class '{class_name}' split: Train={len(splits_data['train'])}, Val={len(splits_data['val'])}, Test={len(splits_data['test'])}\")\n",
    "    print(\"âœ… Video dataset splitting complete.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path, num_frames_to_extract):\n",
    "    \"\"\"\n",
    "    Extracts a specified number of evenly spaced frames from a video.\n",
    "    Returns a list of frames (numpy arrays).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "\n",
    "    if total_frames == 0:\n",
    "        cap.release()\n",
    "        print(f\"Warning: Video {video_path} has 0 frames.\")\n",
    "        return []\n",
    "        \n",
    "    if total_frames < num_frames_to_extract:\n",
    "        # If fewer frames than desired, take all available frames\n",
    "        # And duplicate the last frame to meet num_frames_to_extract\n",
    "        print(f\"Warning: Video {video_path} has {total_frames} frames, less than desired {num_frames_to_extract}. Taking all and padding.\")\n",
    "        frame_indices = list(range(total_frames))\n",
    "    else:\n",
    "        # Select evenly spaced frames\n",
    "        frame_indices = np.linspace(0, total_frames - 1, num_frames_to_extract, dtype=int)\n",
    "\n",
    "    collected_frames_count = 0\n",
    "    last_frame = None\n",
    "    for i in sorted(list(set(frame_indices))): # Use set to avoid duplicate indices from linspace if num_frames_to_extract > total_frames\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "            last_frame = frame\n",
    "            collected_frames_count +=1\n",
    "        else:\n",
    "            # This might happen if cap.set fails near the end of video\n",
    "            print(f\"Warning: Could not read frame {i} from {video_path}, even though total_frames={total_frames}\")\n",
    "            if last_frame is not None: # Duplicate last good frame if we can't read\n",
    "                frames.append(last_frame.copy()) \n",
    "            else: # If no frames read yet and one fails, this is an issue\n",
    "                break \n",
    "\n",
    "\n",
    "    # Pad with the last frame if we still don't have enough (e.g. if total_frames was very small)\n",
    "    while len(frames) < num_frames_to_extract and last_frame is not None:\n",
    "        frames.append(last_frame.copy())\n",
    "    \n",
    "    # If no frames were extracted at all and we need some\n",
    "    if not frames and num_frames_to_extract > 0:\n",
    "        print(f\"Critical Warning: No frames extracted from {video_path}. Returning empty list.\")\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    return frames[:num_frames_to_extract] # Ensure exact number\n",
    "\n",
    "\n",
    "def process_video_splits_for_frames(video_split_dir_root, yolo_output_root, num_frames_per_video):\n",
    "    \"\"\"\n",
    "    Iterates through train/val/test splits of videos, extracts frames,\n",
    "    and saves them into the YOLO classification dataset structure.\n",
    "    \"\"\"\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        current_video_split_dir = os.path.join(video_split_dir_root, split_name)\n",
    "        yolo_target_split_dir = os.path.join(yolo_output_root, split_name)\n",
    "        os.makedirs(yolo_target_split_dir, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(current_video_split_dir):\n",
    "            print(f\"Video split directory not found: {current_video_split_dir}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing videos in: {current_video_split_dir} for YOLO '{split_name}' set.\")\n",
    "        for class_name in os.listdir(current_video_split_dir):\n",
    "            video_class_dir = os.path.join(current_video_split_dir, class_name)\n",
    "            yolo_target_class_dir = os.path.join(yolo_target_split_dir, class_name)\n",
    "            os.makedirs(yolo_target_class_dir, exist_ok=True)\n",
    "\n",
    "            if not os.path.isdir(video_class_dir):\n",
    "                continue\n",
    "\n",
    "            video_files = [f for f in os.listdir(video_class_dir) if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
    "            for video_file in tqdm(video_files, desc=f\"Extracting frames for {class_name} ({split_name})\"):\n",
    "                video_full_path = os.path.join(video_class_dir, video_file)\n",
    "                video_base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "                extracted_frames = extract_frames_from_video(video_full_path, num_frames_per_video)\n",
    "\n",
    "                for i, frame_img in enumerate(extracted_frames):\n",
    "                    frame_filename = f\"{video_base_name}_frame_{i:03d}{IMAGE_SAVE_FORMAT}\"\n",
    "                    frame_output_path = os.path.join(yolo_target_class_dir, frame_filename)\n",
    "                    try:\n",
    "                        cv2.imwrite(frame_output_path, frame_img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving frame {frame_output_path}: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Frame extraction for YOLOv8 classification dataset complete at: {yolo_output_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Split the raw video dataset\n",
    "    print(\"--- STEP 1: Splitting Raw Video Dataset ---\")\n",
    "    # Check if video split path already exists and has content (e.g., train folder)\n",
    "    if not (os.path.exists(os.path.join(VIDEO_SPLIT_PATH, \"train\")) and \\\n",
    "            os.listdir(os.path.join(VIDEO_SPLIT_PATH, \"train\"))):\n",
    "        split_success = split_video_dataset(RAW_VIDEO_DATASET_PATH, VIDEO_SPLIT_PATH, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
    "        if not split_success:\n",
    "            print(\"Halting due to error in video dataset splitting.\")\n",
    "            exit()\n",
    "    else:\n",
    "        print(f\"Video splits already found at '{VIDEO_SPLIT_PATH}'. Skipping video splitting.\")\n",
    "\n",
    "    # Step 2: Extract frames from the split videos and save in YOLO format\n",
    "    print(\"\\n--- STEP 2: Extracting Frames for YOLOv8 Classification ---\")\n",
    "    # Check if YOLO dataset dir exists and has content (e.g., train folder)\n",
    "    if not (os.path.exists(os.path.join(YOLO_FRAME_DATASET_ROOT, \"train\")) and \\\n",
    "            os.listdir(os.path.join(YOLO_FRAME_DATASET_ROOT, \"train\"))):\n",
    "        process_video_splits_for_frames(VIDEO_SPLIT_PATH, YOLO_FRAME_DATASET_ROOT, N_FRAMES_TO_EXTRACT)\n",
    "    else:\n",
    "        print(f\"YOLO frame dataset already found at '{YOLO_FRAME_DATASET_ROOT}'. Skipping frame extraction.\")\n",
    "    \n",
    "    print(\"\\n--- Preprocessing for YOLOv8-cls Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## Training YOLOv8-cls Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_DATASET_ROOT = os.path.join(\"SignLanguage_Processed_Frames\", \"YOLO_Frames_Dataset\")\n",
    "MODEL_TYPE = 'yolov8n-cls.pt'  # Start with nano, can try 'yolov8s-cls.pt', etc.\n",
    "EPOCHS = 100  # Number of training epochs\n",
    "IMG_SIZE = 224 # Standard image size for classification models, YOLO will resize\n",
    "BATCH_SIZE = 32 # Adjust based on your GPU memory\n",
    "PROJECT_NAME = 'runs/slr_yolo_frame_cls_train'\n",
    "EXPERIMENT_NAME = 'exp_frames'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.path.exists(YOLO_DATASET_ROOT):\n",
    "        print(f\"ERROR: Dataset directory not found: {YOLO_DATASET_ROOT}\")\n",
    "        print(\"Please run the 'preprocess_frames_for_yolov8_cls.py' script first.\")\n",
    "        return\n",
    "\n",
    "    # Load a pretrained YOLOv8-cls model\n",
    "    model = YOLO(MODEL_TYPE)\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"\\n--- Starting YOLOv8-cls Training ---\")\n",
    "    print(f\"Dataset: {YOLO_DATASET_ROOT}\")\n",
    "    print(f\"Model: {MODEL_TYPE}\")\n",
    "    print(f\"Epochs: {EPOCHS}\")\n",
    "    print(f\"Image Size: {IMG_SIZE}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "    results = model.train(\n",
    "        data=YOLO_DATASET_ROOT,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        patience=10,  # Early stopping patience\n",
    "        workers=4,    # Number of dataloader workers (adjust based on your CPU)\n",
    "        project=PROJECT_NAME,\n",
    "        name=EXPERIMENT_NAME,\n",
    "        # device='0' # Specify GPU device if you have multiple, otherwise auto-detect\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Training Complete ---\")\n",
    "    print(f\"Results saved in: {os.path.join(PROJECT_NAME, EXPERIMENT_NAME)}\")\n",
    "\n",
    "    # Optional: Evaluate on the validation set explicitly\n",
    "    print(\"\\n--- Evaluating on Validation Set ---\")\n",
    "    val_results = model.val()\n",
    "    print(\"Validation Metrics:\", val_results.results_dict) # Or explore other attributes of val_results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
