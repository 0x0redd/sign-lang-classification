# ğŸ–ï¸ Reconnaissance de Langue des Signes - Classification d'Actions

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble du Projet](#vue-densemble-du-projet)
2. [Architecture Technique](#architecture-technique)
3. [MÃ©thodologie et Approche](#mÃ©thodologie-et-approche)
4. [PrÃ©processing des DonnÃ©es](#prÃ©processing-des-donnÃ©es)
5. [Architecture du ModÃ¨le](#architecture-du-modÃ¨le)
6. [RÃ©sultats et Performance](#rÃ©sultats-et-performance)
7. [Application Web Flask](#application-web-flask)
8. [Installation et Utilisation](#installation-et-utilisation)
9. [Structure du Projet](#structure-du-projet)
10. [Technologies UtilisÃ©es](#technologies-utilisÃ©es)

---

## ğŸ¯ Vue d'ensemble du Projet

Ce projet implÃ©mente un systÃ¨me de reconnaissance de langue des signes basÃ© sur l'intelligence artificielle, capable de classifier des actions/signes Ã  partir de vidÃ©os. Le systÃ¨me utilise une combinaison de dÃ©tection d'objets (YOLOv8), d'extraction de points clÃ©s (MediaPipe), et d'apprentissage profond (LSTM) pour identifier quatre classes d'objets informatiques : **clavier**, **disque dur**, **ordinateur**, et **souris**.

### ğŸ¯ Objectifs
- DÃ©tecter et classifier automatiquement les signes de langue des signes
- Fournir une interface web intuitive pour l'upload et la prÃ©diction
- Atteindre une prÃ©cision Ã©levÃ©e avec un modÃ¨le robuste
- CrÃ©er un pipeline complet de traitement vidÃ©o

---

## ğŸ—ï¸ Architecture Technique

### Pipeline de Traitement
```
VidÃ©o d'entrÃ©e â†’ DÃ©tection YOLO â†’ Extraction MediaPipe â†’ SÃ©quence LSTM â†’ PrÃ©diction
```

### Composants Principaux
1. **YOLOv8** : DÃ©tection des rÃ©gions d'intÃ©rÃªt (mains/personnes)
2. **MediaPipe Hands** : Extraction de 21 points clÃ©s par main
3. **LSTM** : ModÃ¨le de sÃ©quence pour la classification temporelle
4. **Flask** : Interface web pour l'interaction utilisateur

---

## ğŸ”¬ MÃ©thodologie et Approche

### 1. DÃ©tection et Localisation
- **YOLOv8n** : ModÃ¨le lÃ©ger pour la dÃ©tection de personnes/mains
- **Seuil de confiance** : 0.4 pour filtrer les dÃ©tections faibles
- **ROI (Region of Interest)** : Extraction des zones contenant les mains

### 2. Extraction de Points ClÃ©s
- **MediaPipe Hands** : 21 points clÃ©s par main (x, y normalisÃ©s)
- **Support multi-mains** : Jusqu'Ã  2 mains simultanÃ©ment
- **CoordonnÃ©es normalisÃ©es** : Adaptation Ã  diffÃ©rentes rÃ©solutions

### 3. Traitement Temporel
- **SÃ©quence fixe** : 30 frames par vidÃ©o
- **Padding/Truncation** : Standardisation de la longueur
- **Features par frame** : 84 dimensions (2 mains Ã— 21 points Ã— 2 coordonnÃ©es)

---

## ğŸ“Š PrÃ©processing des DonnÃ©es

### Configuration des ParamÃ¨tres
```python
# ParamÃ¨tres MediaPipe
MAX_NUM_HANDS_MEDIAPIPE = 2
MIN_DETECTION_CONF_MEDIAPIPE = 0.5
MIN_TRACKING_CONF_MEDIAPIPE = 0.5

# ParamÃ¨tres de sÃ©quence
NUM_FRAMES_PER_VIDEO = 30
NUM_KEYPOINTS_PER_HAND = 21
NUM_COORDS_PER_KEYPOINT = 2
INPUT_SIZE = 84  # 2 Ã— 21 Ã— 2
```

### Pipeline de PrÃ©processing
1. **Extraction vidÃ©o** : Lecture frame par frame
2. **DÃ©tection YOLO** : Identification des ROIs
3. **Extraction MediaPipe** : Points clÃ©s des mains
4. **Normalisation** : CoordonnÃ©es relatives Ã  l'image
5. **SÃ©quenÃ§age** : Padding/truncation Ã  30 frames
6. **Stockage HDF5** : Format optimisÃ© pour l'apprentissage

### Dataset Final
- **199 vidÃ©os** au total
- **4 classes** : clavier, disque dur, ordinateur, souris
- **RÃ©partition** : 139 train / 40 validation / 20 test
- **Format** : HDF5 avec mÃ©tadonnÃ©es JSON

---

## ğŸ§  Architecture du ModÃ¨le

### LSTMClassifier
```python
class LSTMClassifier(L.LightningModule):
    def __init__(self, input_size=84, hidden_size=256, num_layers=2, 
                 num_classes=4, dropout=0.3, learning_rate=1e-3, weight_decay=1e-4):
```

### CaractÃ©ristiques du ModÃ¨le
- **Type** : LSTM bidirectionnel
- **Couches cachÃ©es** : 256 unitÃ©s
- **Nombre de couches** : 2
- **Dropout** : 0.3 pour la rÃ©gularisation
- **ParamÃ¨tres** : 877K paramÃ¨tres entraÃ®nables
- **Taille estimÃ©e** : 3.51 MB

### Optimisation
- **Optimiseur** : AdamW avec weight decay
- **Scheduler** : ReduceLROnPlateau
- **Monitoring** : F1-score macro pour la validation
- **Early stopping** : Patience de 10 Ã©poques

---

## ğŸ“ˆ RÃ©sultats et Performance

### MÃ©triques Finales (Test Set)
```
Test Accuracy: 80.0%
Test F1-Score (Macro): 78.7%
Test Loss: 0.814
```

### Rapport de Classification DÃ©taillÃ©
```
              precision    recall  f1-score   support

     clavier       1.00      1.00      1.00         5
  disque_dur       0.57      0.80      0.67         5
  ordinateur       0.83      1.00      0.91         5
      souris       1.00      0.40      0.57         5

    accuracy                           0.80        20
   macro avg       0.85      0.80      0.79        20
weighted avg       0.85      0.80      0.79        20
```

### Analyse des Performances
- **Clavier** : Performance parfaite (100% precision/recall)
- **Ordinateur** : Excellente performance (91% F1-score)
- **Disque dur** : Performance moyenne (67% F1-score)
- **Souris** : Performance limitÃ©e (57% F1-score)

### ModÃ¨les SauvegardÃ©s
- **Meilleur modÃ¨le** : `best-action-model-epoch=31-val_f1=0.92.ckpt`
- **F1-score validation** : 92%
- **Ã‰poques d'entraÃ®nement** : 31 (early stopping)

---

## ğŸŒ Application Web Flask

### Architecture de l'Application
```python
# Pipeline de prÃ©diction dans app.py
def predict_sign(video_path):
    1. process_video_for_inference()  # Extraction des points clÃ©s
    2. Conversion en tensor          # PrÃ©paration pour le modÃ¨le
    3. Inference LSTM               # PrÃ©diction
    4. Softmax                     # ProbabilitÃ©s
    5. Retour des rÃ©sultats        # Classe + confiance
```

### FonctionnalitÃ©s
- **Upload vidÃ©o** : Support MP4, AVI, MOV, MKV, WEBM
- **Taille maximale** : 16 MB
- **PrÃ©diction temps rÃ©el** : Traitement immÃ©diat
- **Nettoyage automatique** : Suppression des fichiers temporaires
- **Gestion d'erreurs** : Messages d'erreur dÃ©taillÃ©s

### Interface Utilisateur
- **Template HTML** : Interface moderne et responsive
- **Feedback visuel** : Affichage des rÃ©sultats
- **Gestion des erreurs** : Messages utilisateur clairs

---

## ğŸš€ Installation et Utilisation

### PrÃ©requis
```bash
# Python 3.9+
# CUDA (optionnel, pour GPU)
# 8GB+ RAM recommandÃ©
```

### Installation
```bash
# 1. Cloner le repository
git clone <repository-url>
cd sign-lang-classification

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. VÃ©rifier les fichiers requis
python run_app.py
```

### Fichiers Requis
- `yolov8n.pt` : ModÃ¨le YOLO prÃ©-entraÃ®nÃ©
- `data-yolo/model.h5` : Dataset prÃ©processÃ©
- `model_yolo/best-action-model-*.ckpt` : ModÃ¨le entraÃ®nÃ©

### Lancement de l'Application
```bash
# MÃ©thode 1 : Script de lancement
python run_app.py

# MÃ©thode 2 : Direct
python app.py

# AccÃ¨s : http://localhost:5000
```

---

## ğŸ“ Structure du Projet

```
sign-lang-classification/
â”œâ”€â”€ ğŸ“„ app.py                    # Application Flask principale
â”œâ”€â”€ ğŸ“„ run_app.py               # Script de lancement avec vÃ©rifications
â”œâ”€â”€ ğŸ“„ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ README.MD               # Documentation (ce fichier)
â”œâ”€â”€ ğŸ“„ yolov8n.pt              # ModÃ¨le YOLO prÃ©-entraÃ®nÃ©
â”‚
â”œâ”€â”€ ğŸ“ SignLanguageDataset/     # Dataset vidÃ©o brut
â”‚   â”œâ”€â”€ ğŸ“ clavier/            # 50 vidÃ©os
â”‚   â”œâ”€â”€ ğŸ“ disque_dur/         # 50 vidÃ©os
â”‚   â”œâ”€â”€ ğŸ“ ordinateur/         # 50 vidÃ©os
â”‚   â””â”€â”€ ğŸ“ souris/             # 49 vidÃ©os
â”‚
â”œâ”€â”€ ğŸ“ data-yolo/              # DonnÃ©es prÃ©processÃ©es
â”‚   â””â”€â”€ ğŸ“„ model.h5            # Dataset HDF5
â”‚
â”œâ”€â”€ ğŸ“ model_yolo/             # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ ğŸ“„ best-action-model-epoch=31-val_f1=0.92.ckpt
â”‚   â”œâ”€â”€ ğŸ“„ best-action-model-epoch=13-val_f1=0.88-v3.ckpt
â”‚   â””â”€â”€ ğŸ“ action_rec_logs/    # Logs d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“ templates/              # Templates Flask
â”‚   â””â”€â”€ ğŸ“„ index.html          # Interface utilisateur
â”‚
â”œâ”€â”€ ğŸ“ uploads/                # Fichiers temporaires
â””â”€â”€ ğŸ“„ model - FINAL .ipynb    # Notebook d'entraÃ®nement
```

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Intelligence Artificielle
- **PyTorch** : Framework de deep learning
- **PyTorch Lightning** : Organisation du code d'entraÃ®nement
- **Ultralytics YOLO** : DÃ©tection d'objets
- **MediaPipe** : Extraction de points clÃ©s
- **TorchMetrics** : MÃ©triques d'Ã©valuation

### Traitement de DonnÃ©es
- **OpenCV** : Traitement vidÃ©o et image
- **NumPy** : Calculs numÃ©riques
- **H5Py** : Stockage de donnÃ©es optimisÃ©
- **Pandas** : Manipulation de donnÃ©es

### Web et Interface
- **Flask** : Framework web
- **Werkzeug** : Utilitaires web
- **HTML/CSS/JavaScript** : Interface utilisateur

### Utilitaires
- **Scikit-learn** : MÃ©triques et validation
- **Matplotlib** : Visualisation
- **TQDM** : Barres de progression

---

## ğŸ” DÃ©tails Techniques AvancÃ©s

### Optimisations ImplÃ©mentÃ©es
1. **DÃ©tection ROI** : YOLO pour rÃ©duire la zone de traitement
2. **Multi-mains** : Support simultanÃ© de 2 mains
3. **Normalisation** : CoordonnÃ©es relatives pour la robustesse
4. **Padding intelligent** : Gestion des vidÃ©os de longueurs variables
5. **Early stopping** : PrÃ©vention du surapprentissage
6. **Learning rate scheduling** : Adaptation automatique du taux d'apprentissage

### Gestion de la MÃ©moire
- **Batch processing** : Traitement par lots pour les vidÃ©os longues
- **Nettoyage automatique** : Suppression des fichiers temporaires
- **Optimisation GPU** : Utilisation efficace de la mÃ©moire CUDA

### Robustesse
- **Gestion d'erreurs** : Traitement des cas d'Ã©chec
- **Validation des entrÃ©es** : VÃ©rification des formats de fichiers
- **Fallback** : DÃ©tection sur image complÃ¨te si YOLO Ã©choue

---

## ğŸ“ Notes de DÃ©veloppement

### DÃ©fis RencontrÃ©s
1. **Synchronisation multi-mains** : Gestion des mains gauche/droite
2. **VariabilitÃ© temporelle** : Standardisation des sÃ©quences
3. **Performance temps rÃ©el** : Optimisation pour l'interface web
4. **Gestion mÃ©moire** : Traitement de vidÃ©os volumineuses

### AmÃ©liorations Futures
1. **Augmentation de donnÃ©es** : Plus de classes et d'exemples
2. **Architecture avancÃ©e** : Transformer ou attention mechanisms
3. **Temps rÃ©el** : PrÃ©diction en streaming
4. **Interface mobile** : Application mobile native

---

## ğŸ“ Support et Contact

Pour toute question ou problÃ¨me :
- **Issues GitHub** : Signaler les bugs
- **Documentation** : Consulter ce README
- **Exemples** : Voir le notebook d'entraÃ®nement

---

*Projet dÃ©veloppÃ© avec â¤ï¸ pour la reconnaissance de langue des signes*
