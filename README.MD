# üñêÔ∏è Reconnaissance de Langue des Signes - Classification d'Actions

## üìã Table des Mati√®res

1. [Vue d'ensemble du Projet](#vue-densemble-du-projet)
2. [Architecture Technique](#architecture-technique)
3. [M√©thodologie et Approche](#m√©thodologie-et-approche)
4. [Pr√©processing des Donn√©es](#pr√©processing-des-donn√©es)
5. [Architecture du Mod√®le](#architecture-du-mod√®le)
6. [R√©sultats et Performance](#r√©sultats-et-performance)
7. [Application Web Flask](#application-web-flask)
8. [Installation et Utilisation](#installation-et-utilisation)
9. [Structure du Projet](#structure-du-projet)
10. [Technologies Utilis√©es](#technologies-utilis√©es)

---

## üéØ Vue d'ensemble du Projet

Ce projet impl√©mente un syst√®me de reconnaissance de langue des signes bas√© sur l'intelligence artificielle, capable de classifier des actions/signes √† partir de vid√©os. Le syst√®me utilise une combinaison de d√©tection d'objets (YOLOv8), d'extraction de points cl√©s (MediaPipe), et d'apprentissage profond (LSTM) pour identifier quatre classes d'objets informatiques : **clavier**, **disque dur**, **ordinateur**, et **souris**.

### üéØ Contexte et Motivation
La langue des signes est un langage visuel qui sert de moyen de communication principal pour des millions de personnes sourdes et malentendantes dans le monde. Elle utilise des gestes des mains, des expressions faciales et des mouvements corporels pour transmettre du sens, formant des syst√®mes linguistiques complexes aussi riches et expressifs que les langues parl√©es. La reconnaissance et l'interpr√©tation de la langue des signes par l'intelligence artificielle repr√©sente une avanc√©e critique dans les technologies d'accessibilit√©, avec le potentiel de combler les √©carts de communication et de cr√©er des environnements num√©riques plus inclusifs.

### üéØ Objectifs Principaux
- **D√©velopper un Pipeline Complet** : Concevoir et impl√©menter un syst√®me complet qui traite les vid√©os brutes via la d√©tection des mains, l'extraction de points cl√©s, la mod√©lisation de s√©quences et la classification pour reconna√Ætre les gestes de langue des signes
- **Impl√©menter des Techniques de Vision par Ordinateur de Pointe** : Exploiter YOLOv8 pour une d√©tection robuste des mains et MediaPipe pour une extraction pr√©cise des points cl√©s
- **Concevoir un Mod√®le de Classification de S√©quences Efficace** : D√©velopper et entra√Æner un r√©seau neuronal bas√© sur LSTM capable d'apprendre les motifs temporels dans les s√©quences de points cl√©s
- **Cr√©er une Solution de D√©ploiement Pratique** : Impl√©menter √† la fois un pipeline d'entra√Ænement complet et une application web conviviale
- **√âvaluer et Valider les Performances** : Effectuer une √©valuation compl√®te en utilisant des m√©triques standard d'apprentissage automatique
- **Assurer l'Accessibilit√© et la Confidentialit√©** : D√©velopper un syst√®me capable de fonctionner hors ligne qui respecte la confidentialit√© des utilisateurs

---

## üèóÔ∏è Architecture Technique

### Pipeline de Traitement
```
Vid√©o d'entr√©e ‚Üí D√©tection YOLO ‚Üí Extraction MediaPipe ‚Üí S√©quence LSTM ‚Üí Pr√©diction
```

### Composants Principaux
1. **YOLOv8** : D√©tection des r√©gions d'int√©r√™t (mains/personnes)
2. **MediaPipe Hands** : Extraction de 21 points cl√©s par main
3. **LSTM** : Mod√®le de s√©quence pour la classification temporelle
4. **Flask** : Interface web pour l'interaction utilisateur

---

## üî¨ M√©thodologie et Approche

### 1. D√©tection et Localisation
- **YOLOv8n** : Mod√®le l√©ger pour la d√©tection de personnes/mains
- **Seuil de confiance** : 0.4 pour filtrer les d√©tections faibles
- **ROI (Region of Interest)** : Extraction des zones contenant les mains

### 2. Extraction de Points Cl√©s
- **MediaPipe Hands** : 21 points cl√©s par main (x, y normalis√©s)
- **Support multi-mains** : Jusqu'√† 2 mains simultan√©ment
- **Coordonn√©es normalis√©es** : Adaptation √† diff√©rentes r√©solutions

### 3. Traitement Temporel
- **S√©quence fixe** : 30 frames par vid√©o
- **Padding/Truncation** : Standardisation de la longueur
- **Features par frame** : 84 dimensions (2 mains √ó 21 points √ó 2 coordonn√©es)

### 4. D√©fis Techniques Adress√©s
- **Complexit√© Temporelle** : Les gestes de langue des signes sont intrins√®quement temporels, n√©cessitant l'analyse de motifs de mouvement dans le temps
- **Variabilit√© Spatiale** : Les positions, orientations et √©chelles des mains peuvent varier consid√©rablement entre individus et conditions d'enregistrement
- **Datasets Limit√©s** : Contrairement aux autres t√¢ches de vision par ordinateur, les datasets de langue des signes √† grande √©chelle sont relativement rares
- **Exigences de Traitement Temps R√©el** : Les applications pratiques n√©cessitent des capacit√©s d'inf√©rence en temps r√©el tout en maintenant une pr√©cision √©lev√©e
- **Accessibilit√© et D√©ploiement** : Les syst√®mes doivent √™tre d√©ployables dans divers environnements avec des ressources informatiques variables

---

## üìä Pr√©processing des Donn√©es

### Configuration des Param√®tres
```python
# Param√®tres MediaPipe
MAX_NUM_HANDS_MEDIAPIPE = 2
MIN_DETECTION_CONF_MEDIAPIPE = 0.5
MIN_TRACKING_CONF_MEDIAPIPE = 0.5

# Param√®tres de s√©quence
NUM_FRAMES_PER_VIDEO = 30
NUM_KEYPOINTS_PER_HAND = 21
NUM_COORDS_PER_KEYPOINT = 2
INPUT_SIZE = 84  # 2 √ó 21 √ó 2
```

### Pipeline de Pr√©processing
1. **Extraction vid√©o** : Lecture frame par frame
2. **D√©tection YOLO** : Identification des ROIs
3. **Extraction MediaPipe** : Points cl√©s des mains
4. **Normalisation** : Coordonn√©es relatives √† l'image
5. **S√©quen√ßage** : Padding/truncation √† 30 frames
6. **Stockage HDF5** : Format optimis√© pour l'apprentissage

### Dataset Final
- **199 vid√©os** au total
- **4 classes** : clavier, disque dur, ordinateur, souris
- **R√©partition** : 139 train / 40 validation / 20 test
- **Format** : HDF5 avec m√©tadonn√©es JSON

### Caract√©ristiques des Vid√©os
- **Dur√©e** : Variable (typiquement 2-5 secondes)
- **R√©solution** : Variable (standardis√©e √† 640√ó640 pendant le pr√©traitement)
- **Taux de frames** : Variable (trait√© √† intervalles fixes)
- **Format** : MP4 avec encodage H.264
- **Contenu** : Individu unique effectuant des gestes de signes isol√©s

---

## üß† Architecture du Mod√®le

### LSTMClassifier
```python
class LSTMClassifier(L.LightningModule):
    def __init__(self, input_size=84, hidden_size=256, num_layers=2, 
                 num_classes=4, dropout=0.3, learning_rate=1e-3, weight_decay=1e-4):
```

### Caract√©ristiques du Mod√®le
- **Type** : LSTM bidirectionnel
- **Couches cach√©es** : 256 unit√©s
- **Nombre de couches** : 2
- **Dropout** : 0.3 pour la r√©gularisation
- **Param√®tres** : 877K param√®tres entra√Ænables
- **Taille estim√©e** : 3.51 MB

### Optimisation
- **Optimiseur** : AdamW avec weight decay
- **Scheduler** : ReduceLROnPlateau
- **Monitoring** : F1-score macro pour la validation
- **Early stopping** : Patience de 10 √©poques

---

## üìà R√©sultats et Performance

### M√©triques Finales (Test Set)
```
Test Accuracy: 80.0%
Test F1-Score (Macro): 78.7%
Test Loss: 0.814
```

### Performance d'Inf√©rence
```
Temps de Traitement par Vid√©o : ‚âà 1.8 secondes
Extraction de Frames Vid√©o : 0.12s par vid√©o
D√©tection des Mains (YOLOv8) : 0.03s par frame
Extraction de Points Cl√©s (MediaPipe) : 0.02s par frame
Classification de S√©quence (LSTM) : 0.01s par s√©quence
```

### Rapport de Classification D√©taill√©
```
              precision    recall  f1-score   support

     clavier       1.00      1.00      1.00         5
  disque_dur       0.57      0.80      0.67         5
  ordinateur       0.83      1.00      0.91         5
      souris       1.00      0.40      0.57         5

    accuracy                           0.80        20
   macro avg       0.85      0.80      0.79        20
weighted avg       0.85      0.80      0.79        20
```

### Analyse des Performances
- **Clavier** : Performance parfaite (100% precision/recall)
- **Ordinateur** : Excellente performance (91% F1-score)
- **Disque dur** : Performance moyenne (67% F1-score)
- **Souris** : Performance limit√©e (57% F1-score)

### Mod√®les Sauvegard√©s
- **Meilleur mod√®le** : `best-action-model-epoch=31-val_f1=0.92.ckpt`
- **F1-score validation** : 92%
- **√âpoques d'entra√Ænement** : 31 (early stopping)

### Comparaison avec l'√âtat de l'Art
Les r√©sultats de 80% de pr√©cision s'alignent favorablement avec les pr√©cisions rapport√©es dans la litt√©rature. Les √©tudes utilisant des approches similaires bas√©es sur les points cl√©s ont rapport√© des pr√©cisions allant de 75-90% sur des t√¢ches de vocabulaire limit√©. La pr√©cision de 80% atteinte dans ce travail se situe dans cette fourchette tout en utilisant une architecture de mod√®le relativement compacte et efficace.

---

## üåê Application Web Flask

### Architecture de l'Application
```python
# Pipeline de pr√©diction dans app.py
def predict_sign(video_path):
    1. process_video_for_inference()  # Extraction des points cl√©s
    2. Conversion en tensor          # Pr√©paration pour le mod√®le
    3. Inference LSTM               # Pr√©diction
    4. Softmax                     # Probabilit√©s
    5. Retour des r√©sultats        # Classe + confiance
```

### Fonctionnalit√©s
- **Upload vid√©o** : Support MP4, AVI, MOV, MKV, WEBM
- **Taille maximale** : 16 MB
- **Pr√©diction temps r√©el** : Traitement imm√©diat
- **Nettoyage automatique** : Suppression des fichiers temporaires
- **Gestion d'erreurs** : Messages d'erreur d√©taill√©s
- **Interface responsive** : Compatible desktop et mobile
- **Traitement hors ligne** : Aucune d√©pendance cloud requise
- **Scores de confiance** : Affichage des probabilit√©s pour chaque classe

### Interface Utilisateur
- **Template HTML** : Interface moderne et responsive
- **Feedback visuel** : Affichage des r√©sultats
- **Gestion des erreurs** : Messages utilisateur clairs

---

## üöÄ Installation et Utilisation

### Pr√©requis
```bash
# Python 3.9+
# CUDA (optionnel, pour GPU)
# 8GB+ RAM recommand√©
```

### Installation
```bash
# 1. Cloner le repository
git clone <repository-url>
cd sign-lang-classification

# 2. Installer les d√©pendances
pip install -r requirements.txt

# 3. V√©rifier les fichiers requis
python run_app.py
```

### Fichiers Requis
- `yolov8n.pt` : Mod√®le YOLO pr√©-entra√Æn√©
- `data-yolo/model.h5` : Dataset pr√©process√©
- `model_yolo/best-action-model-*.ckpt` : Mod√®le entra√Æn√©

### Lancement de l'Application
```bash
# M√©thode 1 : Script de lancement
python run_app.py

# M√©thode 2 : Direct
python app.py

# Acc√®s : http://localhost:5000
```

---

## üìÅ Structure du Projet

```
sign-lang-classification/
‚îú‚îÄ‚îÄ üìÑ app.py                    # Application Flask principale
‚îú‚îÄ‚îÄ üìÑ run_app.py               # Script de lancement avec v√©rifications
‚îú‚îÄ‚îÄ üìÑ requirements.txt         # D√©pendances Python
‚îú‚îÄ‚îÄ üìÑ README.MD               # Documentation (ce fichier)
‚îú‚îÄ‚îÄ üìÑ yolov8n.pt              # Mod√®le YOLO pr√©-entra√Æn√©
‚îÇ
‚îú‚îÄ‚îÄ üìÅ SignLanguageDataset/     # Dataset vid√©o brut
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ clavier/            # 50 vid√©os
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ disque_dur/         # 50 vid√©os
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ordinateur/         # 50 vid√©os
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ souris/             # 49 vid√©os
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data-yolo/              # Donn√©es pr√©process√©es
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ model.h5            # Dataset HDF5
‚îÇ
‚îú‚îÄ‚îÄ üìÅ model_yolo/             # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ best-action-model-epoch=31-val_f1=0.92.ckpt
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ best-action-model-epoch=13-val_f1=0.88-v3.ckpt
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ action_rec_logs/    # Logs d'entra√Ænement
‚îÇ
‚îú‚îÄ‚îÄ üìÅ templates/              # Templates Flask
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ index.html          # Interface utilisateur
‚îÇ
‚îú‚îÄ‚îÄ üìÅ uploads/                # Fichiers temporaires
‚îî‚îÄ‚îÄ üìÑ model - FINAL .ipynb    # Notebook d'entra√Ænement
```

---

## üõ†Ô∏è Technologies Utilis√©es

### Intelligence Artificielle
- **PyTorch** : Framework de deep learning
- **PyTorch Lightning** : Organisation du code d'entra√Ænement
- **Ultralytics YOLO** : D√©tection d'objets
- **MediaPipe** : Extraction de points cl√©s
- **TorchMetrics** : M√©triques d'√©valuation

### Traitement de Donn√©es
- **OpenCV** : Traitement vid√©o et image
- **NumPy** : Calculs num√©riques
- **H5Py** : Stockage de donn√©es optimis√©
- **Pandas** : Manipulation de donn√©es

### Web et Interface
- **Flask** : Framework web
- **Werkzeug** : Utilitaires web
- **HTML/CSS/JavaScript** : Interface utilisateur

### Utilitaires
- **Scikit-learn** : M√©triques et validation
- **Matplotlib** : Visualisation
- **TQDM** : Barres de progression

---

## üîç D√©tails Techniques Avanc√©s

### Optimisations Impl√©ment√©es
1. **D√©tection ROI** : YOLO pour r√©duire la zone de traitement
2. **Multi-mains** : Support simultan√© de 2 mains
3. **Normalisation** : Coordonn√©es relatives pour la robustesse
4. **Padding intelligent** : Gestion des vid√©os de longueurs variables
5. **Early stopping** : Pr√©vention du surapprentissage
6. **Learning rate scheduling** : Adaptation automatique du taux d'apprentissage

### Gestion de la M√©moire
- **Batch processing** : Traitement par lots pour les vid√©os longues
- **Nettoyage automatique** : Suppression des fichiers temporaires
- **Optimisation GPU** : Utilisation efficace de la m√©moire CUDA

### Robustesse
- **Gestion d'erreurs** : Traitement des cas d'√©chec
- **Validation des entr√©es** : V√©rification des formats de fichiers
- **Fallback** : D√©tection sur image compl√®te si YOLO √©choue

---

## üìù Notes de D√©veloppement

### D√©fis Rencontr√©s
1. **Synchronisation multi-mains** : Gestion des mains gauche/droite
2. **Variabilit√© temporelle** : Standardisation des s√©quences
3. **Performance temps r√©el** : Optimisation pour l'interface web
4. **Gestion m√©moire** : Traitement de vid√©os volumineuses
5. **Taille limit√©e du dataset** : 199 vid√©os pour 4 classes
6. **Variabilit√© des conditions d'enregistrement** : √âclairage, angles de cam√©ra, styles de signes

### Limitations Actuelles
- **Repr√©sentation des caract√©ristiques** : Utilisation uniquement des points cl√©s des mains, ignorant les expressions faciales et la posture corporelle
- **Mod√©lisation temporelle** : Longueur de s√©quence fixe de 30 frames peut ne pas capturer optimalement la structure temporelle naturelle des signes
- **Architecture du mod√®le** : Les r√©seaux LSTM ont des limitations inh√©rentes pour les d√©pendances √† long terme
- **Sensibilit√© aux conditions** : Performance d√©grad√©e avec des angles de cam√©ra inhabituels, un √©clairage m√©diocre ou des occlusions

### Am√©liorations Futures
1. **Expansion du Dataset** : Entra√Æner le mod√®le sur un dataset beaucoup plus large et diversifi√©
2. **Int√©gration Multi-Modale** : Incorporer les points cl√©s du visage et de la posture corporelle
3. **Architectures Avanc√©es** : Explorer les Transformers, GRUs ou les r√©seaux de convolution temporelle
4. **Augmentation de Donn√©es** : Techniques d'augmentation au niveau des points cl√©s
5. **Inf√©rence Temps R√©el** : Optimisation du pipeline pour l'inf√©rence webcam en temps r√©el
6. **Reconnaissance Continue** : Extension de la reconnaissance de signes isol√©s √† la langue des signes continue
7. **Personnalisation** : Syst√®mes adaptatifs qui apprennent les styles de signes individuels

---

## üìû Support et Contact

Pour toute question ou probl√®me :
- **Issues GitHub** : Signaler les bugs
- **Documentation** : Consulter ce README
- **Exemples** : Voir le notebook d'entra√Ænement

## üéì Informations Acad√©miques

### Auteurs
- **Othmane FERRAH**
- **Hicham BENLMAHI** 
- **Soufian EL KARCHAL**

### Institution
- **D√©partement** : Informatique et G√©nie Informatique
- **Programme** : Licence en Sciences Math√©matiques et Informatique (SMI)
- **Ann√©e Acad√©mique** : 2024/2025

### Projet
- **Type** : Projet de fin d'√©tudes
- **Sujet** : D√©veloppement d'un Syst√®me de Reconnaissance de Langue des Signes en Temps R√©el Utilisant l'Apprentissage Profond et la Vision par Ordinateur
- **Supervision** : Pr. [Nom du Superviseur]

## üìö R√©f√©rences Principales

Ce projet s'appuie sur les travaux de recherche suivants :
- **Adaloglou et al. (2021)** : √âtude compl√®te sur les m√©thodes d'apprentissage profond pour la reconnaissance de langue des signes
- **Camgoz et al. (2020)** : Traduction neuronale de langue des signes
- **Zhang et al. (2020)** : MediaPipe Hands pour le suivi des mains en temps r√©el
- **Ultralytics (2023)** : YOLOv8, nouveau mod√®le de vision par ordinateur de pointe

---

*Projet d√©velopp√© avec ‚ù§Ô∏è pour la reconnaissance de langue des signes*
